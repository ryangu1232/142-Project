{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cf22cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "543a6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(x):\n",
    "    if pd.isna(x):\n",
    "        return \"\"\n",
    "    x = x.strip().lower()\n",
    "    x = re.sub(r\"[^a-z\\s,]\", \"\", x)  # remove punctuation except comma\n",
    "\n",
    "    # Handle Last, First → First Last\n",
    "    if \",\" in x:\n",
    "        last, first = [t.strip() for t in x.split(\",\", 1)]\n",
    "        x = f\"{first} {last}\"\n",
    "        \n",
    "    # Remove double spaces\n",
    "    x = re.sub(r\"\\s+\", \" \", x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rookiestats = pd.read_csv(\"nba-players.csv\")\n",
    "combineStats_df = pd.read_csv(\"nbadraftcombinestats.csv\")\n",
    "\n",
    "rookiestats[\"name\"] = rookiestats[\"name\"].apply(normalize_name)\n",
    "combineStats_df[\"name\"] = combineStats_df[\"PLAYER\"].apply(normalize_name)\n",
    "\n",
    "merged_data = combineStats_df.merge(rookiestats, on=\"name\", how=\"inner\")\n",
    "merged_data = merged_data.drop_duplicates()\n",
    "merged_data = merged_data.drop(columns=[\"name\", \"PAN\", \"HANDL\", \"HANDW\", \"SHUTTLE\", \"PAN\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f25e805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total remaining NaNs: 0\n",
      "YEAR           0\n",
      "PLAYER         0\n",
      "POS            0\n",
      "HGT            0\n",
      "WGT            0\n",
      "BMI            0\n",
      "BF             0\n",
      "WNGSPN         0\n",
      "STNDRCH        0\n",
      "STNDVERT       0\n",
      "LPVERT         0\n",
      "LANE           0\n",
      "SPRINT         0\n",
      "BENCH          0\n",
      "BAR            0\n",
      "PBHGT          0\n",
      "PDHGT          0\n",
      "Unnamed: 0     0\n",
      "gp             0\n",
      "min            0\n",
      "pts            0\n",
      "fgm            0\n",
      "fga            0\n",
      "fg             0\n",
      "3p_made        0\n",
      "3pa            0\n",
      "3p             0\n",
      "ftm            0\n",
      "fta            0\n",
      "ft             0\n",
      "oreb           0\n",
      "dreb           0\n",
      "reb            0\n",
      "ast            0\n",
      "stl            0\n",
      "blk            0\n",
      "tov            0\n",
      "target_5yrs    0\n",
      "POSITION       0\n",
      "dtype: int64\n",
      "\n",
      "Imputation complete! All NaNs should be gone.\n"
     ]
    }
   ],
   "source": [
    "num_cols = merged_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Split numeric columns into:\n",
    "# - columns with at least one non-NaN (usable for KNN)\n",
    "# - columns that are entirely NaN (KNN can't infer anything there)\n",
    "num_cols_for_knn = [c for c in num_cols if not merged_data[c].isna().all()]\n",
    "all_na_num_cols  = [c for c in num_cols if merged_data[c].isna().all()]\n",
    "\n",
    "# Run KNN only if we have something to impute on\n",
    "if num_cols_for_knn:\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    merged_data[num_cols_for_knn] = imputer.fit_transform(merged_data[num_cols_for_knn])\n",
    "\n",
    "# For numeric columns that were all NaN, fill with 0 (or a global mean if you prefer)\n",
    "for c in all_na_num_cols:\n",
    "    # Option 1: fill with 0\n",
    "    merged_data[c] = 0\n",
    "    # Option 2 (alternative): use global mean of all numeric values\n",
    "    # global_mean = merged_data[num_cols_for_knn].to_numpy().mean()\n",
    "    # merged_data[c] = global_mean\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Non-numeric columns → mode imputation\n",
    "# -----------------------------\n",
    "non_num_cols = merged_data.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "for c in non_num_cols:\n",
    "    if merged_data[c].isna().any():\n",
    "        mode = merged_data[c].mode()\n",
    "        if len(mode) > 0:\n",
    "            merged_data[c] = merged_data[c].fillna(mode[0])  # most frequent category\n",
    "        else:\n",
    "            merged_data[c] = merged_data[c].fillna(\"Unknown\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Sanity check: should be 0\n",
    "# -----------------------------\n",
    "print(\"Total remaining NaNs:\", merged_data.isna().sum().sum())\n",
    "print(merged_data.isna().sum())\n",
    "\n",
    "# Save if you want\n",
    "merged_data.to_csv(\"final_data_no_nans.csv\", index=False)\n",
    "print(\"\\nImputation complete! All NaNs should be gone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ad9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
